{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50211639-571d-4ed1-871e-418a39a8640c",
   "metadata": {},
   "source": [
    "This notebook outlines the steps I took to train the Bear Classifier model, which you can see in action here: https://huggingface.co/spaces/emiranda182/bear_classifier\n",
    "\n",
    "Outline\n",
    "1. Set up the environment and import libraries\n",
    "2. Download the dataset\n",
    "3. Organize and verify the data\n",
    "4. Create a DataBlock\n",
    "5. Create a DataLoader\n",
    "6. Train and evaluate the model\n",
    "7. Export the trained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b43cf83-431b-465d-889b-6751177d1865",
   "metadata": {},
   "source": [
    "___________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f262269f-6547-4d2c-9131-37ef059063db",
   "metadata": {},
   "source": [
    "1. Set up the environment and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db10d8df-8029-4782-a576-ad88daf0f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook fastai duckduckgo_search\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f59b47-8026-45a4-b328-55eb343cc01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "from duckduckgo_search import DDGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a7e5a1-5cbe-4a26-b0a0-e9995d04f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to help us download our dataset\n",
    "def search_images(keywords, max_images=200): return L(DDGS().images(keywords, max_results=max_images)).itemgot('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2453bd4c-05c6-43ee-8548-7a1ad7c91e2f",
   "metadata": {},
   "source": [
    "2. Download the dataset: Search for grizzly, black, and teddy bear images, then download them into labeled folders. Note: the original images I used to train the model are included in the repo under the \"bears\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967a835b-e12d-4c05-9df2-11f4c108998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_types = 'grizzly','black','teddy'\n",
    "path = Path('bears')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c876be-6c3a-4be2-98e5-31726c2377da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bear_types = 'grizzly','black','teddy'\n",
    "path = Path('bears')\n",
    "\n",
    "#Downloads roughly 150 images for each bear type\n",
    "if not path.exists():\n",
    "\n",
    "    path.mkdir()\n",
    "    for o in bear_types:\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images(f'{o} bear', 2)\n",
    "        download_images(dest, urls=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894b1384-2d8a-43e7-b6af-05868fb5b5d6",
   "metadata": {},
   "source": [
    "3. Organize and verify the data: Ensure images are saved in the correct subfolders, and remove any failed or corrupted downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c4fa9-45d3-453d-a9e8-f34ff3fd98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = get_image_files(path)\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c34f4-35fc-4188-ba5a-6c55f4a4ea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed.map(Path.unlink);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f81f5dd-5b8b-436b-a5f2-2de03c100550",
   "metadata": {},
   "source": [
    "4. Create a Datablock: Define how images are labeled, split into training/validation sets, and preprocessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f41f7-d1de-4010-94f4-be89d6cdd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a57dc-f3d0-4781-bdb6-127426478d98",
   "metadata": {},
   "source": [
    "5. Create a DataLoader: Use the DataBlock to create a DataLoader, which prepares the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0882a1-69f0-487f-aa28-b7383bbc4545",
   "metadata": {},
   "outputs": [],
   "source": [
    "bears = bears.new(\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms(mult=4))\n",
    "dls = bears.dataloaders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd35cf-2418-4ff9-b770-bbaa51e17a41",
   "metadata": {},
   "source": [
    "6. Train and evaluate the model: Use a pre-trained model ( resnet18) to train the dataset. Watch the results and check how well the model is performing as it learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf781e5-0a5f-477a-b027-dc8c74222b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee19f4b-caca-48c8-8d4b-5f1bba388de1",
   "metadata": {},
   "source": [
    "7. Export the trained model: This .pkl file contains the trained model and is what weâ€™ll use to run inference in production on Hugging Face Spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce65932-3fab-40f2-afaf-ca91af90c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()\n",
    "\n",
    "path = Path()\n",
    "path.ls(file_exts='.pkl') # Should see a 'export.pkl' file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
